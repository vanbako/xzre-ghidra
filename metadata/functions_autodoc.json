{
  "backdoor_entry": "IFUNC resolver entry point. It increments a global invocation counter, calling\n`backdoor_init()` on the second pass so the loader can stage its hooks while glibc thinks it is\nstill choosing a cpuid implementation. Regardless of setup, it finally delegates to\n`_cpuid_gcc` to satisfy liblzma\u2019s original resolver contract.",
  "backdoor_init": "Converts the IFUNC entry context into a GOT patch: it initialises the GOT bookkeeping, locates\nthe cpuid GOT slot via `update_got_address`, swaps the resolver pointer to\n`backdoor_init_stage2`, calls the genuine cpuid to finish initialisation, and then restores the\nslot back to its original target so future calls run the attacker\u2019s resolver without tripping\nsanity checks.",
  "backdoor_init_stage2": "Runs inside the hijacked cpuid resolver. It builds temporary `backdoor_shared_globals_t`,\n`backdoor_hooks_ctx_t`, and `backdoor_setup_params_t` objects, repeatedly calls\n`init_hooks_ctx()` until the shared globals are available, and then hands the bundle to\n`backdoor_setup`. If setup succeeds it never returns (the hooks stay installed); if setup fails\nit zeroes the GOT context and falls back to issuing a real CPUID so liblzma\u2019s resolver still\nfulfils glibc\u2019s contract.",
  "backdoor_setup": "The loader\u2019s main workhorse. It snapshots the caller\u2019s GOT/stack, builds a local\n`backdoor_data_t` describing all observed modules, resolves sshd/libcrypto/liblzma/libc/ld.so\nvia `process_shared_libraries`, initialises the shared globals, and pulls in the\n`backdoor_hooks_data_t` blob sitting inside liblzma. With those pieces it refreshes the\nstring-reference catalogue, configures the global context (payload buffers, sshd/log contexts,\nimport tables), runs the sensitive-data + sshd-metadata discovery routines, and finally rewires\nld.so\u2019s audit tables so `backdoor_symbind64` is invoked for every sshd\u2192libcrypto PLT call. On\nsuccess it copies the updated hook table back into liblzma and leaves the cpuid GOT slot ready\nto resume execution.",
  "bignum_serialize": "Writes a BIGNUM into a length-prefixed buffer, dropping redundant leading zeros so later hashes are stable. Key-fingerprinting helpers call it before running SHA256 over RSA or DSA parameters.",
  "c_memmove": "Private implementation of `memmove` so the object never has to import libc for something this trivial. It detects backwards overlap (`src < dest < src+cnt`) and copies from the end towards the beginning in that case; every other scenario devolves into a forward copy loop. Either way the original `dest` pointer is returned so callers can chain copies just like they would with the libc version.",
  "c_strlen": "Tiny strlen implementation that stage two uses before libc is trustworthy. It simply walks the\nbuffer one byte at a time and returns the length as a signed size, allowing other helpers to\nsanity-check argv/envp strings without resolving libc symbols.",
  "c_strnlen": "Bounded strlen variant used when scanning attacker-controlled buffers. It stops as soon as it\nsees a NUL or reaches `max_len`, returning the limit unchanged if the string is unterminated so\ncallers can treat that as an error.",
  "chacha_decrypt": "Thin wrapper around OpenSSL's ChaCha20 decrypt primitives that operates through the resolved imports table. The backdoor uses it both to unwrap its embedded secrets and to decrypt attacker payloads after they arrive via the monitor channel.",
  "check_argument": "Walks a dash-prefixed argv entry two bytes at a time, mirroring each character so it can flag\nboth upper- and lower-case variants of '-d', '-D', '-E', '-Q', or any option that includes '='\nor '/'. It returns the offending pointer so `process_is_sshd` can treat those switches as a\nhard stop and avoid touching sshd instances launched in debug or non-daemon modes.",
  "check_backdoor_state": "Guards the payload assembly state machine. States 1\u20132 require a populated\n`sshd_payload_ctx` and a minimum payload length (>=0xae) plus a sane body_length pulled from\nthe decrypted header; state 3 tolerates either 3 or 4; and state 0 expects the staging buffer\nto be empty. Any inconsistency zeros the state and sets it to 0xffffffff so the hooks know to\ndiscard buffered data.",
  "contains_null_pointers": "Linear check used before invoking crypto helpers. Given an array of pointers and a count, it\nreports 1 as soon as it encounters a NULL slot, letting callers bail out if any required import\nfailed to resolve.",
  "count_bits": "Classic popcount loop that returns the number of set bits in a 64-bit value. The string-id trie and several instruction filters rely on it when they compress lookup tables for pattern matching.",
  "count_pointers": "Uses `malloc_usable_size()` to measure a pointer array and counts consecutive non-NULL entries\nuntil it hits either a NULL or the allocation boundary. Sensitive-data heuristics call it when\nwalking sshd tables whose length isn\u2019t stored explicitly.",
  "_cpuid_gcc": "GCC-style CPUID shim that dispatches through the individual helper thunks for every supported\nleaf (basic, cache, topology, extended brand strings, etc.). Whatever leaf pointer it chooses\nhas EAX/EBX/ECX/EDX copied into the provided outputs so callers don\u2019t need inline assembly.",
  "decrypt_payload_message": "Decrypts a ChaCha-wrapped `key_payload_t` chunk, copies the plaintext body into the global\nstaging buffer when the advertised length fits, and bumps `ctx->current_data_size`. The body\nis decrypted twice\u2014the second pass keeps the keystream in sync with sshd's original consumer\u2014\nso later packets can continue appending without tearing, and any failure forces the payload\nstate back to 0xffffffff.",
  "dsa_key_hash": "Serialises the DSA public parameters and computes a SHA-256 digest using the resolved libcrypto helpers. The monitor hooks use that fingerprint to recognise host keys referenced by attacker commands without leaking the private material.",
  "elf_contains_vaddr": "Thin wrapper around `elf_contains_vaddr_impl` that keeps the public API surface simple. Every range-checker in the loader funnels through it so the flag handling, recursion guard, and alignment fixes stay centralized, making it easy to detect when a pointer falls outside the parsed ELF image.",
  "elf_contains_vaddr_impl": "Validates that `[vaddr, vaddr + size)` is entirely covered by one or more PT_LOAD segments whose `p_flags` mask includes the requested bits. The helper page-aligns both ends of the interval, walks every loadable program header, and recurses when the range straddles multiple segments so partial overlaps are rechecked piecemeal.\n\nIt refuses to run more than 0x3ea iterations (preventing runaway recursion), insists that the candidate addresses live inside the mapped ELF image, and short-circuits to TRUE when `size` is zero. Callers pass `p_flags` values such as PF_X or PF_W to differentiate text, data, and RELRO spans.",
  "elf_contains_vaddr_relro": "Combines `elf_contains_vaddr` with the GNU_RELRO metadata harvested during `elf_parse`. The range must sit inside a read-only PT_LOAD (PF_R), and the module must have advertised a RELRO segment; if so the helper also verifies that `[vaddr, vaddr+size)` falls within the page-aligned RELRO window cached in `elf_info_t`. Anything outside that protected span returns FALSE, which prevents the loader from treating writable data as RELRO by mistake.",
  "elf_find_function_pointer": "Takes a string-reference catalogue entry, locates the associated RELRO slot, and checks CET landing requirements before returning the pointer. The loader relies on it to identify sshd callback tables\u2014such as monitor handlers\u2014that it will later overwrite with backdoor functions.",
  "elf_find_rela_reloc": "Searches the RELA relocation array for an entry tied to a given code pointer. When `encoded_string_id` is non-zero it is treated as an absolute address inside the module: the helper subtracts `elfbase` to match against `r_addend` and, on success, returns the relocated slot at `r_offset`. When the argument is zero the caller instead wants the raw addend pointer, so the helper immediately returns `elfbase + r_addend`.\n\nA pair of optional range bounds and a resumption index can be supplied in the additional SysV argument registers; if present they force the returned address to fall inside `[low, high]` and let the caller continue scanning from the previous index. Failing to find a match (or discovering that the module never exposed RELA relocations) yields NULL and, if a cursor pointer was provided, stores the position it stopped at.",
  "elf_find_relr_reloc": "Performs the same search as `elf_find_rela_reloc` but against the packed RELR format. It replays the RELR decoding algorithm (literal entry vs bitmap entry), sanity-checks each decoded pointer with `elf_contains_vaddr`, compares the pointed-to value against the requested target address, and optionally enforces a lower/upper bound plus an iteration cursor via the extra argument registers. Returning NULL means there were no RELR records, the address never appeared in the run, or one of the decoded pointers failed validation.",
  "elf_find_string": "Iterates through the cached `.rodata` window, calling `get_string_id` on each byte offset until it encounters a recognizable encoded string. If `*stringId_inOut` is zero the first discovered string wins and its id is written back; otherwise the search continues until an exact id match is found. The optional `rodata_start_ptr` lets callers resume from a previous location or constrain the search to a suffix of the segment.",
  "elf_find_string_reference": "Finds the first instruction that references a specific string literal between the supplied code bounds. The loader uses this pinpoint search to anchor subsequent pattern matching when triangulating hook targets from log messages and status strings.",
  "elf_find_string_references": "Indexes interesting .rodata strings and the instructions that reference them, recording surrounding function bounds for later lookups. Many downstream heuristics consume this table to locate sshd routines and global pointers tied to sensitive behaviour.",
  "elf_get_code_segment": "Finds and caches the first executable PT_LOAD segment. The routine walks the program headers until it sees a segment with PF_X set, computes the runtime address by subtracting the ELF's minimum virtual address from `p_vaddr`, page-aligns both ends, stores the start/size inside `elf_info_t`, and returns the aligned base while writing the computed size through `pSize`. Subsequent calls use the cached values to avoid rescanning the headers.",
  "elf_get_data_segment": "Walks every PT_LOAD segment looking for the last read/write mapping (PF_W|PF_R). Once found it caches three pieces of information: the base of the mapped data (`data_segment_start`), the amount of padding between the end of the file-backed bytes and the next page boundary (`data_segment_alignment`), and the total size of the aligned segment. Callers either request the true segment span (`get_alignment == FALSE`) or the padding region (when TRUE), which is where the implant later tucks the `backdoor_hooks_data_t` structure.",
  "elf_get_got_symbol": "Identical pattern but aimed at the main RELA table: it requires `flags & 2` (meaning RELA records were found) and then calls `elf_get_reloc_symbol` with relocation type 6 (R_X86_64_GLOB_DAT). Successful lookups hand back the writable GOT slot for the symbol so the loader can redirect it; failure means the symbol was not imported through a GOT relocation.",
  "elf_get_plt_symbol": "Looks up the PLT thunk for a given symbol by delegating to `elf_get_reloc_symbol` with relocation type 7 (R_X86_64_JUMP_SLOT). It first makes sure the module actually advertised a PLT relocation table (flag bit 1) and caches its size, then returns the GOT/PLT entry that will be overwritten during hook installation. NULL means either the relocation table was absent or the requested symbol never appeared there.",
  "elf_get_reloc_symbol": "Generic helper that scans an arbitrary relocation array for undefined symbols of a specific relocation type (e.g., GOT vs PLT) and a specific encoded name. It iterates through `num_relocs`, ensures the relocation type matches `reloc_type`, confirms the associated symbol is really an import (`st_shndx == 0`), and then resolves the symbol name via `get_string_id` before comparing it to `encoded_string_id`. When it finds a match it returns the relocated address (`elfbase + r_offset`) so the caller can patch GOT/PLT entries in place.",
  "elf_get_rodata_segment": "Locates the first read-only PT_LOAD segment that lives entirely after the executable code. It first asks `elf_get_code_segment` for the text range so it can ignore overlapping pages, then scans for PF_R-only segments, page-aligns their bounds, and picks the lowest segment whose start is beyond the end of `.text`. The result is cached in `elf_info_t` and handed to callers alongside its size so later routines (string searches, RELRO probes) can reuse the computed window.",
  "elf_parse": "Initialises an `elf_info_t` from an in-memory ELF header: zeroes every field, records the lowest PT_LOAD virtual address, locates the PT_DYNAMIC segment, and caches pointers to the strtab, symtab, relocation tables (PLT, RELA, RELR), GNU hash buckets, version records, and GNU_RELRO metadata. Each pointer retrieved from the dynamic table is validated with `elf_contains_vaddr` so forged headers are rejected.\n\nIt also enforces invariants such as 'only one PT_GNU_RELRO segment', derives the number of dynamic entries, and flips feature bits (`flags`) so later helpers know whether RELR, versym, or gnurelro data is present. Failure to locate the dynamic segment, find the required headers, or keep derived pointers inside mapped memory causes the parse to abort with FALSE.",
  "elf_symbol_get": "Symbol resolver that trusts the GNU hash table the loader extracted earlier. After setting a telemetry bit it walks each hash bucket, validates the bucket and chain addresses, and replays the classic GNU hash lookup to pull `Elf64_Sym` entries out of `.dynsym`. When a candidate symbol has a non-zero value and section index, the helper hashes the associated string with `get_string_id` and compares it against the requested encoded id.\n\nIf a symbol version is supplied it additionally consults `.gnu.version`/`.gnu.version_d`: the version index is read from `versym`, then matched against the verifier definitions by walking the linked `verdef` list and comparing the underlying string id. Returning NULL means either the target symbol is missing, the module did not advertise GNU hash+version tables, or the string/relocation pointers failed validation.",
  "elf_symbol_get_addr": "Convenience layer on top of `elf_symbol_get`: look up the symbol, make sure it is defined (both `st_value` and `st_shndx` are non-zero), and then turn the symbol value into a process address by adding it to `elf_info->elfbase`. Returning NULL indicates either the symbol does not exist or it represents an import/resolver stub that lacks a concrete address.",
  "extract_payload_message": "Scans an sshbuf blob for either 'ssh-rsa-cert-v01@openssh.com' or 'rsa-sha2-256', walks the\nsurrounding length fields (network byte order), and ensures the modulus chunk fits within the\ncaller-provided buffer. When it finds a match it rewrites sshbuf->d to point at the modulus\npayload and returns its size so the command decoder knows how many bytes to decrypt.",
  "fake_lzma_alloc": "Companion to `fake_lzma_free` that turns the liblzma allocation API into a symbol resolver. The `opaque` parameter is treated as an `elf_info_t *`, the requested `size` is reinterpreted as an `EncodedStringId`, and it simply returns whatever `elf_symbol_get_addr()` produces. The `nmemb` argument is ignored because the helper is never asked to allocate real memory\u2014it only masquerades as an allocator long enough to bootstrap symbol lookups inside ld.so.",
  "fake_lzma_free": "No-op placeholder that exists solely to satisfy the liblzma allocator interface the implant exposes. The loader wires this stub into `lzma_allocator.free` until it can swap in the genuine host callbacks, so any invocation is guaranteed to do nothing other than prove that the fake allocator is still active.\n\nHaving an inert body keeps the import surface small while still exporting a correctly typed symbol, and it gives the runtime a reliable indicator that a caller incorrectly tried to free memory through the bootstrap allocator.",
  "fd_read": "Wraps libc\u2019s read with retry logic. It refuses to run without both `read` and\n`__errno_location`, loops on EINTR, and aborts with -1 when the helper sees EOF before the\nrequested byte count. Successful reads consume the entire length so callers can treat any\nnon-zero return as \"buffer filled\".",
  "fd_write": "Mirror of `fd_read`: it requires valid write/errno pointers, retries on EINTR, and treats short\nwrites as fatal so callers either send the entire buffer or receive -1. It is the plumbing used\nwhenever the implant forges monitor messages.",
  "find_add_instruction_with_mem_operand": "Locates ADD instructions that update memory at a given address, capturing the scale of the increment. The scoring logic uses it to observe how sshd mutates counters so the implant can tag sensitive buffers.",
  "find_addr_referenced_in_mov_instruction": "Scans a referenced function for MOV instructions that materialise an address inside the supplied data window. The backdoor uses it to recover struct-field pointers (for example the monitor sockets) so it can redirect them to its own handlers.",
  "find_call_instruction": "Disassembles forward until it encounters a CALL opcode and reports both the instruction and target. The hook finder uses it to locate indirect dispatcher sites in sshd so the injected shims can be spliced in safely.",
  "find_dl_audit_offsets": "Drives the full ld.so preparation sequence: resolves several EC/EVP helpers, maps\n`_dl_audit_symbind_alt`, finds the `l_name` displacement, extracts `_dl_naudit/_dl_audit`, and\nfinally discovers the `l_audit_any_plt` byte plus its mask. It also copies the basename of\nlibcrypto into `hooks->ldso_ctx` so the forged link_map name matches the original string.",
  "find_dl_naudit": "Parses `rtld_global_ro` for the `GLRO(dl_naudit)` string, locates the matching LEA inside\n`_dl_audit_symbind_alt`, and from there recovers the addresses of `_dl_naudit` and\n`_dl_audit` within ld.so. It also resolves a few extra libcrypto helpers (EVP_MD_CTX_free,\nDSA_get0_{pqg,pub_key}) so the later monitor hooks can fingerprint host keys. The discovered\npointers are stored inside `hooks->ldso_ctx`.",
  "find_function": "Combines the prologue scan with a forward sweep to determine both the start and end addresses of a function. Backdoor initialization relies on it when it needs exact bounds for copying original bytes or scheduling follow-up pattern searches.",
  "find_function_prologue": "Sweeps backward from a code pointer looking for a plausible function prologue based on decoded instruction patterns. The runtime loader uses it to recover entry points in stripped sshd/libc images before installing hooks.",
  "find_instruction_with_mem_operand": "Convenience wrapper that searches for MOV/LEA forms touching a specific address and reports the displacement. It feeds higher-level routines that locate struct fields for the backdoor's runtime patch table.",
  "find_instruction_with_mem_operand_ex": "Performs a generic sweep for any instruction that touches memory, applying a caller-supplied predicate to filter the operands. The loader routes specialised searches through it when reconstructing complex data flows in sshd.",
  "find_lea_instruction": "Finds the next LEA instruction in the stream and returns operand details. The backdoor uses this to recover base-plus-offset calculations that point at data structures it later siphons.",
  "find_lea_instruction_with_mem_operand": "Restricts the LEA search to instructions that materialize a specific memory address, including displacement checks. It is invoked when the implant needs to confirm the exact offset of sshd globals before patching them.",
  "find_link_map_l_audit_any_plt": "Starting from the `_dl_audit_symbind_alt` body, it looks for the LEA that materialises\n`link_map::l_name`, confirms the register usage matches the displacement into the link_map, and\nthen seeds an `instruction_search_ctx_t` that calls\n`find_link_map_l_audit_any_plt_bitmask`. Success means both the offset of the byte and the mask\nneeded to set/clear it are recorded in `hooks->ldso_ctx`.",
  "find_link_map_l_audit_any_plt_bitmask": "Scans `_dl_audit_symbind_alt` for the MOV/TEST sequence that inspects `link_map::l_audit_any_plt`.\nIt tracks which register held the computed displacement, validates that the test uses a single\nset bit, and saves both the target address (relative to the libname offset) and the mask. Those\nvalues are later used to toggle sshd/libcrypto into \"audited\" mode when the custom audit\ninterface is installed.",
  "find_link_map_l_name": "Walks the liblzma link_map table (pulled from the `.data` copy baked into the object) to find\nthe entry whose RELRO tuple matches the live liblzma image, then computes the displacement of\neach `link_map::l_name` pointer relative to that snapshot. Along the way it resolves the\n`_dl_audit_symbind_alt` template, several libc helpers (exit, setresuid/gid, system, shutdown),\nand caches the displacement so later code can rewrite libcrypto's `l_name` field when posing\nas an audit module.",
  "find_mov_instruction": "Searches for MOV instructions with configurable load/store semantics and hands back the matched operands. It underpins many of the signature searches the implant runs while deriving addresses for secret data or resolver trampolines.",
  "find_mov_lea_instruction": "Iterates through MOV and LEA instructions that move pointers into registers, honouring load/store direction flags. The loader uses it to chase GOT writes and frame setups when it has to recover sensitive pointers for the backdoor context.",
  "find_reg2reg_instruction": "Searches a code range for register-to-register moves while enforcing CET-safe constraints. The implant uses it when it needs to follow pointer copies without touching memory operands during its pattern hunts.",
  "find_string_reference": "Scans for instructions that reference a given string literal via RIP-relative addressing and records the instruction span. Secret-data hunters use it to line up code blocks that print or parse target strings so hooks can score them.",
  "_get_cpuid_modified": "Wrapper around `_cpuid_gcc` that first invokes `backdoor_entry` with the high-bit leaf to make\nsure the loader ran, checks the returned maximum leaf, and only executes the requested CPUID if\nthe CPU claims to support it. This is the exported symbol glibc binds, so the loader\u2019s work is\ntriggered before any sshd thread asks for cpuid data.",
  "get_elf_functions_address": "Same pattern for the `elf_functions_t` dispatch table: start from the relocation-safe sentinel (`elf_functions_offset` lives near `fake_lzma_allocator_offset` in `.data`) and advance 12 struct slots to arrive at the live table. The convoluted pointer math lets the object carry offsets instead of absolute addresses, which keeps the relocation surface tiny while still giving the loader a stable way to reach its helper vtable.",
  "get_lzma_allocator": "Returns the `lzma_allocator` sub-structure embedded inside the fake allocator blob. Callers use it when they need to hand liblzma-style callbacks to another routine (e.g., passing an allocator into a liblzma API) while still pointing `opaque` at the implant's `elf_info_t`.",
  "get_lzma_allocator_address": "Manual pointer arithmetic that recovers the runtime address of the fake `fake_lzma_allocator_t` blob without requiring relocatable absolute addresses. The compiler emits a sentinel (`fake_lzma_allocator`) followed by padding, so this helper starts at that symbol and steps through the struct 12 times, effectively adding the baked-in 0x160-byte offset that lands on the real allocator instance the loader populated at build time.",
  "get_string_id": "Traverses the embedded string-trie and returns the encoded identifier for a runtime string. Every heuristic that matches sshd literals\u2014logging, monitor messages, protocol banners\u2014goes through this to avoid shipping plaintext strings in the payload.",
  "get_tls_get_addr_random_symbol_got_offset": "Seeds `ctx->got_ctx.got_ptr` and `ctx->got_ctx.got_offset` with the canned values associated\nwith the fake `__tls_get_addr` symbol. The loader uses those numbers as the starting point for\n`update_got_address`, which refines them into the concrete GOT entry address.",
  "hook_EVP_PKEY_set1_RSA": "Observes when sshd wraps an RSA key in an EVP_PKEY, hands the key to `run_backdoor_commands`, and then falls through to the true OpenSSL routine. It guarantees the backdoor sees host keys even if the decrypt hook never fires.",
  "hook_RSA_get0_key": "Lets the backdoor inspect an RSA key whenever sshd queries it by calling `run_backdoor_commands` first, then invoking the genuine RSA_get0_key. The original behaviour is preserved, but the implant captures the key material for later use.",
  "hook_RSA_public_decrypt": "Replaces `RSA_public_decrypt` with a wrapper that feeds the RSA handle and ciphertext into `run_backdoor_commands` before deciding whether to call the real function. Once the audit symbind hook is active, this is the primary trigger that lets attacker payloads run.",
  "init_elf_entry_ctx": "Seeds an `elf_entry_ctx_t` prior to running the IFUNC resolvers. It records the address of `cpuid_random_symbol`, captures the caller's return address from the saved frame (slot 3), recomputes the GOT offset via `update_got_offset`, primes the cpuid GOT index with `update_cpuid_got_index`, and clears the cached `got_ptr` so the resolver will refill it. The context is later consumed by the GOT patching code that splices the malicious cpuid stub into sshd.",
  "init_hooks_ctx": "        Primes the transient `backdoor_hooks_ctx_t` with pointers to the shared hooks blob, the\naudit shim (`backdoor_symbind64`), and the mm/EVP hook entry points. When `shared` is still NULL it\n        seeds the structure with the static hook addresses and returns 0x65 so the caller can retry\n        once the shared globals are available; otherwise it returns 0 to signal that hook setup may\n        proceed.\n    ",
  "init_imported_funcs": "Validates that the loader resolved all 0x1d imports and, crucially, that the RSA-related PLT\nentries are non-null. If any of the three slots are missing it drops in loader callbacks\n(`backdoor_init_stage2` and `init_shared_globals`) so the hook table never points at garbage.\nOtherwise it reports success and the caller can start re-pointing the mm hooks at the real\nOpenSSL routines.",
  "init_ldso_ctx": "Restores every ld.so flag the implant may have touched: it writes the saved auditstate\nbindflags back to libcrypto/sshd, unsets the copied `l_name` byte, clears the\n`l_audit_any_plt` bit with the mask recovered earlier, and zeros `_dl_naudit`/`_dl_audit` so\nthe dynamic linker no longer believes an audit module is registered. Stage two calls it on\nfailure paths so sshd resumes with the original ld.so state.",
  "init_shared_globals": "Seeds the shared global block with the mm/EVP hook entry points and a pointer to the lone\n`global_ctx` instance. Every hook consults this block at runtime, so the function simply wires\nthe exported function pointers into the struct and returns success once the pointer checks\npass.",
  "is_endbr64_instruction": "Checks whether the bytes at the current cursor encode an ENDBR64 landing pad, including the CET prefix variations. The pattern scanners call it so the backdoor can safely step past CET trampolines while carving prologues to patch.",
  "is_gnu_relro": "Obfuscated equality test for PT_GNU_RELRO. Instead of comparing `p_type` directly against `0x6474e552`, the code adds the caller supplied `addend` (always `0xa0000000`) and checks for the magic constant, which makes the instruction stream look less like a straightforward RELRO probe in the object file.",
  "is_range_mapped": "Userland page-probe that avoids importing `mincore(2)`. The helper aligns the requested address downward, then walks one page at a time toward `addr + length`, invoking the host's `pselect` with NULL fd sets and the page pointer passed in as the signal mask argument. If `pselect` faults with EFAULT the page is unmapped, otherwise the loop continues until every page succeeds. The routine relies on `ctx->libc_imports` to surface both `pselect` and `__errno_location`, and it refuses to touch addresses below 0x01000000 to avoid probing NULL or vsyscall.",
  "j_tls_get_addr": "Jumps straight into the real `__tls_get_addr` resolver. The backdoor keeps both this wrapper and the trapping stub exported so it can redirect GOT entries during setup: hooks call `j_tls_get_addr` when they want the legit resolver, while the relocation constants point at the trapping version until the loader patches things up.",
  "lzma_alloc": "Counterpart to `lzma_free` that also traps. Once the loader installs the fake allocator the GOT entry is overwritten with `fake_lzma_alloc`; if execution ever reaches this stub it means the relocation failed and the safest option is to abort immediately.",
  "lzma_check_init": "Intentional trap stub for liblzma's `lzma_check_init()`. Until the loader patches this export to the real liblzma routine it simply calls `halt_baddata()`, guaranteeing that any accidental execution stops immediately and signalling that someone tried to run the object outside the curated runtime.",
  "lzma_free": "Placeholder export for `lzma_free()` that funnels straight into `halt_baddata()`. The backdoor never expects this stub to run because it always routes work through the fake allocator, so entering it implies the GOT was not repointed and the process halts rather than corrupting memory.",
  "main_elf_parse": "Given a `main_elf_t` that already points at ld.so's ELF header, this routine parses the interpreter, looks up `__libc_stack_end`, and then calls `process_is_sshd` to verify that the captured runtime really belongs to sshd. If the checks pass it stores the resolved `__libc_stack_end` pointer back through `main_elf->__libc_stack_end`, giving later stages an easy way to reach sshd's argument/environment block.",
  "mm_answer_authpassword_hook": "Responds to MONITOR_REQ_AUTHPASSWORD by either replaying the canned buffer stored in the\nglobal payload context or synthesising a minimal success packet on the fly. The hook emits the\nreply through fd_write(), mirrors sshd's bookkeeping by updating the monitor context at\nlVar1+0xa0, and returns 1 so the monitor thread believes password authentication succeeded\nwithout ever consulting sshd.",
  "mm_answer_keyallowed_hook": "Drives the decrypted payload state machine: it extracts sshbuf chunks from the monitor\nmessage, pieces together and decrypts the staged payload, validates signatures against the\ncached host_pubkeys, optionally runs privilege escalation (setresuid/setresgid + system), and\nonly then patches mm_answer_keyverify/mm_answer_authpassword before tail-calling the genuine\nmm_answer_keyallowed. On failure it resets the payload_state and, if instructed, exits sshd\nentirely.",
  "mm_answer_keyverify_hook": "Uses the cached monitor payload context to send the prebuilt MONITOR_ANS_KEYVERIFY reply\ndirectly to the requesting socket. After the write it restores the original\nmm_answer_keyverify function pointer so sshd's dispatcher advances as if the verifier\nsucceeded, and if the write fails it terminates sshd via the libc exit import to avoid leaving\na half-patched state.",
  "mm_log_handler_hook": "Interposes on sshd's log handler, ignoring every message when logging is globally disabled or\nselectively rewriting the 'Connection closed by ... (preauth)' lines when filtering mode is\nenabled. It rebuilds safe format strings on the stack, calls sshd_log() to emit the sanitised\nmessage, and leaves syslog alone unless the caller requested suppression via cmd flags.",
  "process_is_sshd": "Replays sshd's early argument parsing from the saved stack pointer: it verifies the argc/argv\ntuple is sane, checks argv[0] hashes to '/usr/sbin/sshd', walks every argument through\n`check_argument`, and then ensures envp pointers either live on the stack or inside the ELF\n.data segment. Any environment string that maps to a known identifier (get_string_id != 0)\naborts the run, which keeps the loader from running inside unexpected binaries or\ninstrumentation harnesses.",
  "process_shared_libraries": "Wrapper around `process_shared_libraries_map` that first resolves `r_debug` out of ld.so,\ncopies the caller-provided struct into a local scratch copy, and feeds the scratch copy into\nthe map-walker. On success it propagates the filled-in handles (and libc import table) back to\nthe caller so later stages never have to read `r_debug` again.",
  "process_shared_libraries_map": "Traverses the `r_debug` chain looking for entries whose basename hashes to sshd, libcrypto,\nld.so, liblzma, libc, and libsystemd. For each match it verifies the map is sane\n(non-overlapping, dyn pointer matches the parsed ELF) and, once all handles are collected,\nresolves the RSA/EVP PLT stubs in sshd and primes the liblzma data segment pointer that holds\nthe hooks blob. The resulting pointers populate `backdoor_shared_libraries_data_t` for the\nrest of the loader.",
  "resolve_libc_imports": "Treats `link_map *libc` as another ELF image, runs `elf_parse` to populate `elf_info_t`, and\nthen allocates trampolines for `read` and `__errno_location` via the fake allocator shim. Only\nwhen both imports succeed does it mark `libc_imports_t` as ready, ensuring subsequent socket\nI/O helpers can operate without touching the real PLT.",
  "rsa_key_hash": "Serialises the RSA exponent and modulus and hashes them with SHA256 using the resolved imports. The monitor hooks rely on that digest to confirm that an attacker request refers to a known host key before acting.",
  "run_backdoor_commands": "Central dispatcher invoked from the RSA hooks: it parses the forged modulus, decrypts staged payload chunks, verifies the ED448 signature, toggles sshd configuration/logging, and, if necessary, escalates through `sshd_proxy_elevate`. Every command the backdoor accepts flows through this routine before control returns to libcrypto.",
  "secret_data_append_from_address": "Runs the singleton appender against either a provided code pointer or the caller's return address, letting hooks fingerprint themselves at runtime. The recorded bits contribute to the secret_data blob used for payload decryption.",
  "secret_data_append_from_call_site": "Validates the caller site, shifts the requested bits, and returns TRUE (or the bypass flag). It is sprinkled at sensitive call sites so the secret_data ledger captures that execution passed through trusted glue.",
  "secret_data_append_from_code": "Walks a trusted code range, optionally skipping until the first CALL, and records bits for each qualifying register-to-register instruction. The backdoor uses it to encode integrity fingerprints into the secret_data bitmap before decrypting payload material.",
  "secret_data_append_from_instruction": "Evaluates a decoded instruction and, when it matches expected patterns, sets a bit inside `global_ctx->secret_data`. The loader uses it to encode \"this function looks intact\" attestation bits that are later consumed during payload decryption.",
  "secret_data_append_item": "Calls the singleton appender only when a supplied index is non-zero, making it easy to gate optional fingerprint operations. The various secret-data tables use it to share common code while respecting per-item enable flags.",
  "secret_data_append_items": "Iterates an array of secret_data_item descriptors, assigning indexes on the fly and invoking the supplied appender for each. This batches the dozens of integrity checks that run during backdoor_setup into a single call.",
  "secret_data_append_singleton": "Performs a one-off fingerprint of a function: finds its start, validates the instruction stream, shifts the requested number of bits, and marks the operation id as complete. Setup routines call it to attest critical helpers before relying on them for decryption.",
  "secret_data_get_decrypted": "Runs a two-stage ChaCha20 decrypt to recover the embedded secret-data blob using keys stored alongside the payload. Other helpers request it whenever they need the ED448 key or command constants.",
  "sha256": "Invokes EVP_Digest/Evp_sha256 through the imported function table to hash arbitrary buffers. It fingerprints host keys and payload components so the command verifier can prove authenticity without linking libcrypto statically.",
  "sshbuf_bignum_is_negative": "Checks whether a serialized BIGNUM is negative by inspecting its buffer layout. Secret-data scanners invoke it to ignore malformed key material pulled from sshd buffers.",
  "sshbuf_extract": "Validates a runtime sshbuf using offsets recorded in the global context and returns its data pointer and size. The backdoor uses it to access monitor messages safely even when structure layouts shift across builds.",
  "sshd_configure_log_hook": "Validates that the caller supplied a log context with writable handler slots, decides whether\nlogging should be globally muted or merely filtered, and (when filtering) ensures all required\nformat strings are present. It then captures the original handler/context pair, optionally\nrewrites them if the pointers already point inside sshd, and drops in `mm_log_handler_hook` so\nforged monitor messages can suppress incriminating log lines.",
  "sshd_find_main": "Obtains sshd's code segment, decodes the entry stub, and looks for the instruction pair that\nloads the real `sshd_main` address right before the `__libc_start_main` thunk. When it sees a\nmatching MOV/LEA that targets the GOT slot for libc's entry point it records the discovered\n`sshd_main`, resolves EVP_Digest/EVP_sha256, and caches the stub pointers inside\n`imported_funcs` so later recon code can reuse them without reopening libcrypto.",
  "sshd_find_monitor_field_addr_in_function": "Sweeps a candidate sshd routine for MOV/LEA instructions that load a BSS slot into a\nregister, confirms that the pointer flows unmodified into a nearby call to `mm_request_send`,\nand returns the underlying data-section address. The helper lets\n`sshd_find_monitor_struct` recover individual monitor fields (send/recv fds, sshbuf pointers,\netc.) even when the surrounding function is stripped.",
  "sshd_find_monitor_struct": "Calls `sshd_find_monitor_field_addr_in_function` across ten monitor-related routines\n(accept/recv/send helpers, channel handlers, etc.), tallies how many times each BSS address\nshows up, and picks the consensus pointer when at least five hits agree. The winner is stored\nin `ctx->struct_monitor_ptr_address` so later hooks can dereference monitor->m_sendfd/m_recvfd\ndirectly.",
  "sshd_find_sensitive_data": "Bootstraps the entire sensitive-data discovery pipeline: emits bookkeeping entries for the\nsecret-data mirroring code, allocates libcrypto stubs (EVP_DigestVerify*, EVP_CIPHER_CTX_new,\nEVP_chacha20), finds `sshd_main`/`uses_endbr64`, gathers code/data segment bounds, and runs\nboth the xcalloc and KRB5CCNAME heuristics. It scores whichever pointers were found, keeps the\nhigher-confidence candidate, and writes it into `ctx->sshd_sensitive_data` before returning\nsuccess.",
  "sshd_get_client_socket": "Prefers using the recovered monitor struct: depending on DIR_READ/DIR_WRITE it fetches\nmonitor->m_sendfd or m_recvfd, verifies the fd by issuing a zero-length read that tolerates\nEINTR, and returns it on success. If the monitor pointer is missing or the fd is bad/EBADF it\nfalls back to `sshd_get_usable_socket`'s fd scanner.",
  "sshd_get_sensitive_data_address_via_krb5ccname": "Starts at the string reference to 'KRB5CCNAME', disassembles forward until it sees the\ngetenv result copied into memory, and only accepts stores that land inside sshd's .data/.bss\nwindow with the expected -0x18 displacement pattern. That combination reliably identifies the\nsensitive_data struct that holds host key material after sshd propagates the Kerberos cache\npath.",
  "sshd_get_sensitive_data_address_via_xcalloc": "Locates the call site that matches the cached xcalloc reference, walks the following basic\nblock looking for the MOV/LEA that parks the return value in .bss, and collects up to sixteen\nsuch stores. Whenever it sees three consecutive slots separated by 8 bytes (pointer,\npointer+8, pointer+0x10) it treats the lowest address as the sensitive_data candidate\ngenerated during sshd's early zero-initialisation.",
  "sshd_get_sensitive_data_score": "Combines the three per-function heuristics with weighting: `demote_sensitive_data` and `main`\nscores get doubled and added together, then the `do_child` score is tacked on. Candidates must\nexceed the global threshold (>=8) before the pointer is published to the rest of the implant.",
  "sshd_get_sensitive_data_score_in_demote_sensitive_data": "Disassembles the `demote_sensitive_data` helper referenced in the string table and returns\nthree points if it ever references the candidate pointer. That routine is highly specific to\nthe real sensitive_data block, so even a single hit is treated as strong evidence.",
  "sshd_get_sensitive_data_score_in_do_child": "Uses the string-reference catalogue to find `do_child`, then counts how often it dereferences\nthe candidate pointer at offsets 0 and +0x10. A hit on the base yields one point, and seeing\nmultiple accesses to the +0x10 slot adds up to two more, producing a score that reflects how\ntightly the child process manipulates the structure.",
  "sshd_get_sensitive_data_score_in_main": "Checks sshd's main() for memory operands that touch the candidate pointer at offsets 0, +8,\nand +0x10. The heuristic rewards routines that touch the base and +0x10 entries while\npenalising ones that never reference +8, generating a small signed score that later gets\ndoubled in the aggregate calculation.",
  "sshd_get_sshbuf": "Walks the cached monitor structure to locate the sshbuf that carries key-exchange data, falling back to heuristics if necessary. The payload executor calls it before mining modulus bytes from the session state.",
  "sshd_get_usable_socket": "Linearly probes file descriptors 0\u201363, calling shutdown(fd, SHUT_RDWR) and treating errors\nlike EINVAL/ENOTCONN as evidence that the descriptor is alive but idle. Each qualified\ndescriptor increments a counter, and when it matches `socket_index` the fd is returned so the\nimplant can recycle sshd's sockets without holding a monitor struct.",
  "sshd_log": "Wraps sshd's sshlogv() implementation by rebuilding a va_list on the stack, saving/restoring\nXMM registers when necessary, and then tail-calling the resolved function pointer in the log\ncontext. Every monitor hook routes formatted log lines through here so it matches OpenSSH's\nlogging ABI without needing libc wrappers.",
  "sshd_patch_variables": "Requires the mm_answer_authpassword hook to be resolved, then optionally forces\nPermitRootLogin to 'yes', disables PAM when requested, and swaps the monitor authpassword\nfunction pointer to the implant's hook. If no explicit monitor_reqtype override is provided it\nderives the current request ID from the original function pointer so replies continue matching\nsshd's state machine.",
  "sshd_proxy_elevate": "Implements the privileged side of the monitor command channel. Depending on the cmd_type and\nflags it may disable PAM, short-circuit non interactive requests, or exit when instructed. For\nKEYALLOWED-style payloads it hunts for the staged ChaCha-wrapped blob on the stack, decrypts\nit with the recovered key, generates a signed MONITOR_REQ_KEYALLOWED packet using freshly\nbuilt RSA/BIGNUM objects and the attacker-provided modulus/exponent, and writes the forged\nrequest over the selected monitor or fallback socket. It then pushes any extra sshbuf data\nwhen needed, drains the reply, and honours 'exit' or 'wait for response' semantics encoded in\nthe original command.",
  "__tls_get_addr": "Same trap pattern as `lzma_check_init`: the compiled object ships a dummy `__tls_get_addr` that halts if invoked. The loader adjusts the GOT to point at `j_tls_get_addr` (and eventually the host's resolver); leaving this stub in place makes unexpected execution obvious and prevents the payload from silently calling an incomplete resolver.",
  "update_cpuid_got_index": "Copies the relocation constants baked into `tls_get_addr_reloc_consts` into\n`ctx->got_ctx.cpuid_fn`. That value is the GOT index of the cpuid resolver inside liblzma, so\nlater code can patch the correct slot without rescanning the PLT stub.",
  "update_got_address": "Disassembles liblzma's `__tls_get_addr` PLT stub, accounts for the short/long JMP encodings,\nand then computes the true GOT entry by applying the stub's 32-bit displacement. The resulting\npointer is cached in `ctx->got_ctx.got_ptr` and later consumed when swapping the cpuid GOT slot\nover to the implant's resolver.",
  "update_got_offset": "Copies `_Llzma_block_buffer_decode_0` into `ctx->got_ctx.got_offset`, giving the loader a\nreproducible base when translating between the baked relocation constants and runtime\naddresses. It pairs with `update_got_address` during the cpuid GOT patch.",
  "validate_log_handler_pointers": "Replays sshd's code that writes `log_handler` and `log_handler_ctx`: starting from the\nstring-reference index for the logging functions it walks forward, verifies the LEA that\nmaterialises the handler storage, re-identifies the function via `find_function`, and then\nconfirms that both candidate pointers are written via MOV [mem],reg instructions in that\nwindow. Only when both stores are observed does it accept the pair as the real\nlog_handler/log_handler_ctx slots.",
  "verify_signature": "Computes the host-key hash, loads the attacker\u2019s ED448 public key, and runs EVP_DigestVerify on the supplied signature. This gate keeps the backdoor command channel\u2014only messages signed with the embedded ED448 key reach the executor.",
  "x86_dasm": "Implements a minimal x86-64 decoder that walks a buffer while tracking instruction metadata. Every search helper in the loader uses it to reason about sshd and ld.so machine code without linking a full disassembler, giving the backdoor reliable patch coordinates at runtime.",
  "xzre_globals": "Data blob emitted by the exporter that instantiates the singleton objects declared in\n`xzre_types.h`\u2014notably `global_ctx`, the backing `backdoor_hooks_data_t`, and the\n`backdoor_shared_globals_t` pointer table. Reverse-engineering it documents which offsets hold\nthe live loader state (payload buffers, resolved imports, sshd/log contexts) so\nmetadata-driven tooling can reason about the structure even when the binary image changes."
}
